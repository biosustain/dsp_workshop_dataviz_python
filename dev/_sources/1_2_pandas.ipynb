{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas (for data to plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard data manipulation framework in Python (many others make use of at least part of its functionalities or are compatible with it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not going in-depth - we are just showing some basic functionalities which are important for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "IN_COLAB = \"COLAB_GPU\" in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "\n",
    "fname = Path(\"data\") / \"growth\" / \"fake_growth_data.csv\"\n",
    "if IN_COLAB:\n",
    "    fname = (\n",
    "        \"https://raw.githubusercontent.com/biosustain/dsp_workshop_dataviz_python\"\n",
    "        \"/refs/heads/main/data/growth/fake_growth_data.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA I/O (Input/Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load in some fake data made to fit some growth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the first few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also omit .head() and it will automatically shorten the output based\n",
    "on your rendering settings.\n",
    "\n",
    "> These settings are controlled by pandas display options, such as\n",
    "> `pd.options.display.max_rows` and `pd.options.display.max_columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Write it to a File\n",
    "E.g. after some data manipulation you wish to save the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a dataframe to a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"fake_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.read_csv()` and `.to_csv()` are the general input/output functions (among some more).\n",
    "Meaning: they work for other common files too (`.txt`, `.tsv`) and some more domain-specific\n",
    "files that are however in a (somewhat) tabular format (e.g. `.vcf`).\n",
    "In other words - as long as it looks like a table, you can read /write to it,\n",
    "regardless of the file extension.\n",
    "\n",
    "To demonstrate, let us save it to a `.tsv` file. The difference is that it is\n",
    "**tab**-separated values instead of **comma**-separated values in a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"fake_data.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can make sense to omit the index column, as Pandas automatically creates\n",
    "one when you read it, even if it already exists.\n",
    "(Otherwise you specify e.g. `index_col=0` when reading it - try it out to see the difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"fake_data.tsv\", sep=\"\\t\", index=False)\n",
    "pd.read_csv(\"fake_data.tsv\", sep=\"\\t\", index_col=None).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also read/write zipped file. Pandas will try to detect it automatically,\n",
    "but you can specify it yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"fake_data.tsv.gz\", sep=\"\\t\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Rename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names are written in a human-readable format, with spaces and brackets.\n",
    "It can be a good practice however to write them in a more programming-friendly way.\n",
    "We can easily do it by using a dictionary with the syntax\n",
    "`{<old-name>: <new-name>}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_renamed = df.rename(\n",
    "    columns={\n",
    "        \"SFN concentration (µM)\": \"sfn_conc_mumolar\",\n",
    "        \"time (h)\": \"time_h\",\n",
    "        \"Bacterial growth (OD600)\": \"bact_growth_od600\",\n",
    "    }\n",
    ")\n",
    "df_col_renamed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this - or many other operations - inplace for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(\n",
    "    columns={\n",
    "        \"SFN concentration (µM)\": \"sfn_conc_mumolar\",\n",
    "        \"time (h)\": \"time_h\",\n",
    "        \"Bacterial growth (OD600)\": \"bact_growth_od600\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Filtering by Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have data for aerobic and anaerobic conditions. If we are only\n",
    "interested in looking at e.g. the aerobic data, we can do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aerobic = df[df[\"condition\"] == \"Aerobic\"]\n",
    "df_aerobic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter by multiple conditions. For example, get all anaerobic data from\n",
    "DMSO, where the OD600 is below a value of 0.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi_condition = df[\n",
    "    (df[\"condition\"] == \"Anaerobic\")\n",
    "    & (df[\"sfn_conc_mumolar\"] == \"DMSO\")\n",
    "    & (df[\"bact_growth_od600\"] < 0.4)\n",
    "]\n",
    "df_multi_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Adding Data By Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of data transformation is adding in new variables based on other columns in the\n",
    "table. This can be also just for plotting. For example, we could wish to color our\n",
    "plot on whether our bacteria are in their stationary phase or not. Then, we would add\n",
    "a variable called `is_stationary()` that we use to subset parts of our data for\n",
    "plotting (we will show how later with seaborn). We use NumPy for this purpose with\n",
    "the syntax\n",
    "`(<condition(s)>, <output-if-true>, <output-if-false>)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_stationary\"] = np.where(df[\"bact_growth_od600\"] >= 0.55, True, False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Aggregating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we are more interested in the maximum or average OD or alike in our experiment.\n",
    "We could just use `.max()` for example but it would give us the maximum value across\n",
    "all variables. If however we wish to distinguish between different cases\n",
    "(like anaerobic/aerobic), then it makes sense to group our data first.\n",
    "Here, we show how to aggregate across all replicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep_agg = (\n",
    "    df.groupby([\"time_h\", \"condition\", \"sfn_conc_mumolar\"])[\"bact_growth_od600\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "df_rep_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put our command in brackets so we can write it out in multiple lines to show it\n",
    "better. We also reset the index at the end to transform the `pd.Series` object back into\n",
    "a `pd.DataFrame` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also aggregate multiple things at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi_agg = (\n",
    "    df.groupby([\"time_h\", \"condition\", \"sfn_conc_mumolar\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"is_stationary\": [\"count\"],\n",
    "            \"bact_growth_od600\": [\n",
    "                \"min\",\n",
    "                \"mean\",\n",
    "                \"max\",\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "df_multi_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Adding Data by Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we just added the `is_stationary` variable based on a guess. We could also\n",
    "do it more programmatically. We do it here in two steps:\n",
    "1. Adding a column indicating the maximum OD600 for that condition-sfn-replicate, minus a tolerance\n",
    "2. Conditioning on that new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stationary_od\"] = df.groupby([\"condition\", \"sfn_conc_mumolar\", \"replicate\"])[\n",
    "    \"bact_growth_od600\"\n",
    "].transform(lambda col: col.max() - 0.1)\n",
    "df[\"is_stationary\"] = np.where(\n",
    "    df[\"bact_growth_od600\"] >= df[\"stationary_od\"], True, False\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That tolerance could also be calculated in a similar way, e.g. based on the standard\n",
    "deviation (we leave that as an exercise if you want to try it out yourself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c07bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more useful transformations, but we end here by having shown some that\n",
    "you could already use in more advanced plots.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
